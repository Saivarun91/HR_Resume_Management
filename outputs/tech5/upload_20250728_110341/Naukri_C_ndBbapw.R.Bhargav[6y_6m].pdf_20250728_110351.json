{
    "RESUME_RELEVANCE_SCORE": 75,
    "ROLE_FIT_SCORE": 70,
    "ATS_SCORE": 80,
    "KEYWORD_MATCH_SCORE": 75,
    "MATCHED_KEYWORDS": [
        "Power BI",
        "SQL",
        "Excel",
        "Tableau",
        "Reporting",
        "Dashboards",
        "Data",
        "Analytics",
        "Retail",
        "KPI",
        "Forecasting",
        "Data Sources",
        "Data Transformation",
        "Inventory",
        "SaaS",
        "Azure",
        "SQL Server",
        "ETL",
        "Data Modeling",
        "Data Visualization",
        "Stakeholder Goals",
        "Communication",
        "Problem Solving",
        "Requirements",
        "Security",
        "Data Analysis",
        "Data Validation",
        "KPIs",
        "Cloud",
        "Data Warehousing",
        "Data Flows",
        "Data Model",
        "Data Ingestion",
        "Data Quality",
        "Merchandising",
        "API",
        "Online Channels",
        "Marketplaces",
        "FMCG",
        "D2C Brands",
        "Cross Functional",
        "Team Collaboration"
    ],
    "MISSING_KEYWORDS": [
        "Inventory Planning",
        "Inventory Optimization",
        "Demand Forecasting",
        "Supply Chain",
        "Inventory Levels",
        "Replenishment",
        "Store Performance",
        "Forecast Accuracy",
        "Inventory Turnover Ratio",
        "Store Fill Rate",
        "Stock Out",
        "Overstock",
        "Omnichannel Inventory",
        "FOFO franchise models",
        "Working Capital Efficiency",
        "Historical Sales",
        "Seasonality",
        "Marketing Inputs",
        "New Launches",
        "Promotions",
        "Regional Preferences",
        "Min Max levels",
        "Stock Movement",
        "Slow Moving",
        "Overstocked Items",
        "Aging Stock",
        "Pivot Tables",
        "Lookups",
        "Modeling",
        "Planning Logic",
        "ABC Classification",
        "EOQ",
        "Retail Inventory Planning Tools",
        "ERP Systems",
        "NetSuite",
        "Zoho",
        "Unicommerce",
        "Adherence",
        "Usage"
    ],
    "MISSING_SKILLS": [
        "Inventory Planning",
        "Demand Forecasting",
        "Inventory Optimization",
        "SQL",
        "Advanced Excel (pivot tables, lookups, modeling)",
        "Power BI/Tableau",
        "Forecasting techniques",
        "Planning logic (ABC classification, EOQ, min max)",
        "Retail inventory planning tools",
        "ERP systems (NetSuite, Zoho, Unicommerce, etc.)",
        "Communication skills",
        "Cross functional collaboration"
    ],
    "ROLEMATCHES": {
        "Power BI Developer": 85,
        "Business Intelligence Analyst": 80,
        "Data Analyst": 78,
        "Data Engineer": 72,
        "Reporting Analyst": 70
    },
    "YEARS": 6,
    "INTERVIEW_QUESTIONS": {
        "PSYCHOMETRIC": [
            {
                "questions": "How do you handle a situation where you have to make a critical decision with incomplete information?",
                "answer": "I would gather as much relevant data as possible, consult with stakeholders for additional insights, weigh the potential risks and benefits of each option, and make a decision based on the best available information, while remaining adaptable to new information as it arises."
            },
            {
                "questions": "Describe a time when you had to adapt to a significant change in priorities at work. How did you manage it?",
                "answer": "In my previous role, a major client project was suddenly put on hold. I quickly reassessed my workload, communicated with my team to redistribute tasks, and focused on other high-priority projects, ensuring a smooth transition and minimal disruption."
            },
            {
                "questions": "How do you approach problem-solving when faced with a complex technical challenge?",
                "answer": "I break down the problem into smaller, manageable components, research potential solutions, experiment with different approaches, and systematically test and iterate until I find an effective resolution, documenting each step along the way."
            }
        ],
        "Soft_Skills": [
            {
                "questions": "Describe a time when you had to work with a difficult team member. How did you handle the situation?",
                "answer": "In a past project, I encountered a team member who was resistant to collaboration. I initiated one-on-one conversations to understand their concerns, actively listened to their ideas, and found common ground to foster a more cooperative working relationship, ultimately improving team performance."
            },
            {
                "questions": "How do you ensure clear and effective communication with stakeholders who may not have a technical background?",
                "answer": "I tailor my communication to the audience, avoiding technical jargon and focusing on the business impact of my work. I use visuals, analogies, and simple language to explain complex concepts, ensuring that stakeholders understand the key insights and recommendations."
            },
            {
                "questions": "Share an example of a time when you took initiative to improve a team process or workflow.",
                "answer": "I noticed that our team was spending excessive time on manual data validation. I proposed automating the process using Python scripts, which significantly reduced errors, saved time, and improved overall efficiency, allowing the team to focus on more strategic tasks."
            }
        ],
        "Behavioral": [
            {
                "questions": "Tell me about a time when you had to debug a complex Power BI report under pressure. What steps did you take to resolve the issue?",
                "answer": "Situation: I was tasked with debugging a critical Power BI report that was experiencing refresh failures right before a major presentation to senior management.\nTask: My task was to identify the root cause of the refresh failures and implement a solution as quickly as possible to ensure the report would be ready for the presentation.\nAction: I started by systematically checking the data sources, DAX formulas, and data model relationships. I discovered a DAX logic error that was causing the refresh to fail. I corrected the DAX logic, optimized the data model, and tested the report thoroughly.\nResult: I successfully resolved the refresh failures, and the Power BI report was ready for the presentation. Senior management was able to gain valuable insights from the report, leading to informed decision-making."
            },
            {
                "questions": "Describe a situation where you had to optimize a slow-performing Power BI report. What techniques did you use to improve its performance?",
                "answer": "Situation: I was assigned to optimize a Power BI report that was taking a long time to load, impacting user experience and decision-making.\nTask: My task was to identify the bottlenecks in the report and implement techniques to improve its performance.\nAction: I analyzed the DAX queries, data model relationships, and visuals. I identified several areas for improvement, including optimizing DAX formulas, reducing the number of visuals, and implementing data aggregation. I used Power BI Performance Analyzer to identify the most time-consuming queries and visuals.\nResult: I successfully optimized the Power BI report, reducing the load time by 40%. Users were able to access and interact with the report more quickly, leading to improved decision-making and overall satisfaction."
            },
            {
                "questions": "Share an example of a time when you had to integrate data from multiple sources into Power BI for real-time reporting. What challenges did you face, and how did you overcome them?",
                "answer": "Situation: I was tasked with integrating data from multiple sources, including APIs, SQL Server, and Snowflake, into Power BI for real-time reporting.\nTask: My task was to establish connections to these data sources, transform and model the data, and create a unified Power BI report that provided real-time insights.\nAction: I used Power BI connectors to connect to the APIs, SQL Server, and Snowflake. I used Power Query to transform and cleanse the data, and I created relationships between the tables in the data model. I encountered challenges with data consistency and latency.\nResult: I successfully integrated the data from multiple sources into Power BI for real-time reporting. The report provided stakeholders with a comprehensive view of key business metrics, leading to improved decision-making and performance."
            }
        ],
        "Technical_easy": [
            {
                "questions": "What is Power BI, and what are its main components?",
                "answer": "Power BI is a business analytics tool by Microsoft that allows you to visualize data and share insights. Its main components include Power BI Desktop (for report creation), Power BI Service (for publishing and sharing reports), and Power BI Mobile (for viewing reports on mobile devices)."
            },
            {
                "questions": "How do you import data into Power BI?",
                "answer": "Data can be imported into Power BI from various sources such as Excel, SQL Server, databases, cloud services, and more. In Power BI Desktop, you can use the 'Get Data' option to select the data source and import the data."
            },
            {
                "questions": "What are DAX functions in Power BI, and can you give an example?",
                "answer": "DAX (Data Analysis Expressions) is a formula language used in Power BI for calculations and data analysis. An example is the 'SUM' function, which calculates the sum of values in a column."
            }
        ],
        "Technical_medium": [
            {
                "questions": "Explain how you would optimize a Power BI report for better performance.",
                "answer": "To optimize a Power BI report, I would focus on reducing data volume, optimizing DAX queries, using efficient visuals, and minimizing the number of relationships in the data model. I would also leverage features like data aggregation and calculated columns where appropriate."
            },
            {
                "questions": "Describe how you would implement row-level security (RLS) in Power BI.",
                "answer": "Row-level security can be implemented in Power BI by creating roles and filters in Power BI Desktop. You define DAX expressions that filter the data based on the user's role. Then, you publish the report to Power BI Service and assign users to the appropriate roles."
            },
            {
                "questions": "How do you handle incremental refresh in Power BI, and why is it useful?",
                "answer": "Incremental refresh in Power BI allows you to load only the changed or new data into your dataset, rather than refreshing the entire dataset. It is useful for large datasets because it reduces refresh time and resource consumption."
            }
        ],
        "Technical_hard": [
            {
                "questions": "Design a data model in Power BI for a retail company with multiple stores, products, and sales transactions.",
                "answer": "I would design a star schema with fact and dimension tables. The fact table would contain sales transaction data, while dimension tables would include store details, product information, customer details, and date dimensions. Relationships would be established between the fact table and each dimension table using primary and foreign keys."
            },
            {
                "questions": "How would you integrate real-time data from an API into Power BI for live reporting?",
                "answer": "I would use Power BI's built-in connectors or custom connectors to connect to the API. I would configure the data source to refresh at regular intervals (e.g., every few minutes) to capture real-time updates. I would also optimize the API queries to minimize latency and ensure efficient data retrieval."
            },
            {
                "questions": "Describe a scenario where you had to troubleshoot a complex DAX calculation that was returning incorrect results. What steps did you take to identify and resolve the issue?",
                "answer": "I would start by breaking down the DAX calculation into smaller, more manageable components. I would use DAX Studio to evaluate the individual components and identify the source of the error. I would also use the Power BI Performance Analyzer to check for performance bottlenecks and potential issues with the data model. Finally, I would consult with other experts and review the DAX documentation to ensure that I am using the correct syntax and logic."
            }
        ]
    }
}